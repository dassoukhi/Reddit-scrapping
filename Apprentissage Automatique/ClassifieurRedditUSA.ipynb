{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bienvenue sur le Notebook qui réalise de la classification supervisée sur des données de la forme:\n",
    "\n",
    "**Texte descriptif,0\n",
    "Autre texte,1\n",
    "Encore un autre texte,0\n",
    "\n",
    "**(Ici 1 veut dire que le texte parle d'un endroit aux Etats Unis, 0 sinon) \n",
    " \n",
    "**Le but de ce Notebook est de prédire si le texte en question parle d'un endroit aux Etats-Unis ou d'un endroit ailleurs sur la planète\n",
    "\n",
    "**Pour ce faire, nous créons un dataframe qui lis le fichier contenant les données et qui met les textes dans la première colonne que l'on nommera data (variables prédictives), et qui met les 0 et 1 dans une colonne nommée target (variable à prédire)\n",
    "\n",
    "**Nous allons également compter le nombre de textes parlant d'un endroit aux Etats Unis et les autres, afin de nous assurer qu'ils sont représentés dans des proportions à peu près égales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data  target\n",
      "0                               Estes Park Colorado        1\n",
      "1  The most beautiful mountain range in the Dolom...       0\n",
      "2       Sunset burns over Reflections lake in Alaska       1\n",
      "3  Bloodmoon Canyon - Original composited Lunar E...       0\n",
      "4               Sunset reflections in Wasilla Alaska       1\n",
      "dans le csv de départ, il y a  520  photos prises aux USA et  762 photos prises ailleurs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"myfile.csv\",sep=',', header = None, names = ['data', 'target'])\n",
    "print(df.head())\n",
    "list(df.columns)\n",
    "cptUSA=0\n",
    "cptOthers=0\n",
    "for i in df.target:\n",
    "    if i==1:\n",
    "        cptUSA=cptUSA+1\n",
    "    else:\n",
    "        cptOthers= cptOthers+1\n",
    "print(\"dans le csv de départ, il y a \",cptUSA,\" photos prises aux USA et \",cptOthers, \"photos prises ailleurs\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorisation des textes pour qu'ils deviennent utilisables par les modèles de clasification par la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X -> variables prédictive, y -> variable à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectors.toarray()\n",
    "\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On découpe le jeu de données pour avoir 30% du jeu réservé à la validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On utilise la validation croisée pour faire le test de validation sur une partie différente du jeu de de données dix fois de suite et on fait ensuite la moyenne des accuracy trouvées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réalisé en 0.501s\n",
      "Les différentes accuracy pour les 10 évaluations sont : \n",
      " [0.98449612 0.99224806 0.9765625  0.9921875  0.9765625  0.9921875\n",
      " 0.984375   0.984375   0.9921875  0.96875   ] \n",
      "\n",
      "Accuracy moyenne :  0.9843931686046512  standard deviation 0.007818650022855016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "\n",
    "seed=7\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "clf = GaussianNB()\n",
    "\n",
    "scoring = 'accuracy'\n",
    "t0 = time()\n",
    "score = cross_val_score(clf, X, y, cv=k_fold, scoring=scoring)\n",
    "print(\"Réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "print('Les différentes accuracy pour les 10 évaluations sont : \\n',\n",
    "      score,'\\n')\n",
    "print ('Accuracy moyenne : ',score.mean(), \n",
    "       ' standard deviation', score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On teste la méthode de classification linéaire SGDC et on affiche la matrice de confusion et le rapport de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit réalisé en 0.013s\n",
      "Prédiction réalisée en 0.026s\n",
      "\n",
      " accuracy: 0.8697104677060133 \n",
      "\n",
      "\n",
      " matrice de confusion \n",
      " [[474  48]\n",
      " [ 69 307]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       522\n",
      "           1       0.86      0.82      0.84       376\n",
      "\n",
      "    accuracy                           0.87       898\n",
      "   macro avg       0.87      0.86      0.87       898\n",
      "weighted avg       0.87      0.87      0.87       898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', \n",
    "                                      penalty='l2',\n",
    "                                      alpha=1e-3, \n",
    "                                      random_state=42, \n",
    "                                      max_iter=5, tol=None)),\n",
    "               ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=df.data\n",
    "y=df.target\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Fit réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "result = pipeline.predict(X_test)\n",
    "print(\"Prédiction réalisée en %0.3fs\" % (time() - t0))\n",
    "\n",
    "print('\\n accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n",
    "\n",
    "\n",
    "\n",
    "print ('\\n',classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On utilise une GridSearchCV pour tester toutes les combinaisons de paramètres des modèles linéaires et d'arbre de décision, puis on choisit le meilleurs résultat pour chaque modèle et on les compare. (ici, le classifieur linéaire donne une meilleure accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: Linear classifiers\n",
      "Fit réalisé en 0.109s\n",
      "Meilleurs paramètres : {'clf__alpha': 1e-05, 'clf__max_iter': 8, 'clf__penalty': 'l2'}\n",
      "Meilleur score d'accuracy sur l'entrainement: 0.556\n",
      "Prédiction réalisée en 0.002s\n",
      "Score d'accuracy pour les meilleurs paramètres sur jeu de test : 0.667\n",
      "\n",
      " matrice de confusion \n",
      " [[7 3]\n",
      " [4 7]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67        10\n",
      "           1       0.70      0.64      0.67        11\n",
      "\n",
      "    accuracy                           0.67        21\n",
      "   macro avg       0.67      0.67      0.67        21\n",
      "weighted avg       0.67      0.67      0.67        21\n",
      "\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Fit réalisé en 1.497s\n",
      "Meilleurs paramètres : {'clf__criterion': 'gini', 'clf__max_depth': 5, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5}\n",
      "Meilleur score d'accuracy sur l'entrainement: 0.778\n",
      "Prédiction réalisée en 0.002s\n",
      "Score d'accuracy pour les meilleurs paramètres sur jeu de test : 0.524\n",
      "\n",
      " matrice de confusion \n",
      " [[8 2]\n",
      " [8 3]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.80      0.62        10\n",
      "           1       0.60      0.27      0.37        11\n",
      "\n",
      "    accuracy                           0.52        21\n",
      "   macro avg       0.55      0.54      0.50        21\n",
      "weighted avg       0.55      0.52      0.49        21\n",
      "\n",
      "\n",
      "Classifier avec la meilleur accuracy sur le jeu de test\n",
      " Linear classifiers\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from time import time\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Specification des pipelines\n",
    "# programmation à optimiser par une fonction :)\n",
    "pipeline_SGDC = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                    ('clf', SGDClassifier())])\n",
    "\n",
    "\n",
    "parameters_SGDC = [\n",
    "    {'clf__max_iter': (8,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet')}\n",
    "]\n",
    "\n",
    "pipeline_DT = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                   ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "\n",
    "#param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 5, 8, 10]\n",
    "parameters_DT = [\n",
    "    {'clf__min_samples_leaf': param_range,\n",
    "        'clf__criterion': ['gini', 'entropy'],\n",
    "        'clf__max_depth': param_range,\n",
    "        'clf__min_samples_split': param_range[1:]}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=df.data\n",
    "y=df.target\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "# Creation des GridSearchCV avec les pipelines spécifiques\n",
    "\n",
    "gs_SGDC = GridSearchCV(pipeline_SGDC, \n",
    "                       parameters_SGDC, \n",
    "                       cv=3,\n",
    "                       n_jobs=-1, \n",
    "                       scoring='accuracy')\n",
    "\n",
    "\n",
    "gs_DT = GridSearchCV(pipeline_DT, \n",
    "                     parameters_DT, \n",
    "                     cv=3,\n",
    "                     n_jobs=-1, \n",
    "                     scoring='accuracy')\n",
    "\n",
    "\n",
    "\n",
    "grids = [gs_SGDC, gs_DT]\n",
    "grid_dict={0:'Linear classifiers', 1:'Decision Tree'}\n",
    "\n",
    "best_acc = 0.0\n",
    "best_clf = 0.0\n",
    "best_gs = ''\n",
    "\n",
    "for idx,gs in enumerate(grids):\n",
    "    print('\\nClassifier: %s' % grid_dict[idx])\n",
    "    t0 = time()\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Fit réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print('Meilleurs paramètres : %s' % gs.best_params_)\n",
    "\n",
    "    print(\"Meilleur score d'accuracy sur l'entrainement: %.3f\" % gs.best_score_)\n",
    "    # Prediction sur le jeu de test avec les meilleurs paramètres\n",
    "    t0 = time()\n",
    "    result = gs.predict(X_test)\n",
    "    print(\"Prédiction réalisée en %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    print(\"Score d'accuracy pour les meilleurs paramètres sur jeu de test : %.3f\"  % accuracy_score(y_test, result))\n",
    "\n",
    "    print ('\\n matrice de confusion \\n',confusion_matrix(y_test, result))\n",
    "\n",
    "    print ('\\n',classification_report(y_test, result))\n",
    "    \n",
    "    #Modele avec la meilleure accuracy sur le jeu de test\n",
    "    if accuracy_score(y_test, result) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, result)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "        \n",
    "        \n",
    "        \n",
    "print('\\nClassifier avec la meilleur accuracy sur le jeu de test\\n',\n",
    "      grid_dict[best_clf])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On recommence le processus pour obtenir le modèle du classifieurs linéaire entraîné puis on le compresse avec pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement du fit \n",
      "\n",
      "Fit réalisé en 0.013s\n",
      "Lancement de la prédiction \n",
      "\n",
      "Prédiction réalisée en 0.025s\n",
      "\n",
      " accuracy: 0.8741648106904232 \n",
      "\n",
      "\n",
      " matrice de confusion \n",
      " [[466  56]\n",
      " [ 57 319]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       522\n",
      "           1       0.85      0.85      0.85       376\n",
      "\n",
      "    accuracy                           0.87       898\n",
      "   macro avg       0.87      0.87      0.87       898\n",
      "weighted avg       0.87      0.87      0.87       898\n",
      "\n",
      "\n",
      "Sauvegarde du pipeline grid search\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Recupération des données pour l'exemple\n",
    "#et partir proprement\n",
    "#categories = ['alt.atheism', 'talk.religion.misc',\n",
    "#             'rec.sport.hockey','comp.graphics', 'sci.space']\n",
    "#\n",
    "#news = fetch_20newsgroups(subset='all',\n",
    "#                         categories=categories)\n",
    "\n",
    "df=pd.read_csv(\"myfile.csv\",sep=',', header = None, names = ['data', 'target'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', \n",
    "                                      penalty='l2',\n",
    "                                      alpha=1e-05, \n",
    "                                      random_state=42, \n",
    "                                      max_iter=5, \n",
    "                                      tol=None)),\n",
    "               ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=df.data\n",
    "y=df.target\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "print (\"Lancement du fit \\n\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Fit réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "print (\"Lancement de la prédiction \\n\")\n",
    "result = pipeline.predict(X_test)\n",
    "print(\"Prédiction réalisée en %0.3fs\" % (time() - t0))\n",
    "\n",
    "print('\\n accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n",
    "\n",
    "\n",
    "\n",
    "print ('\\n',classification_report(y_test, result))\n",
    "\n",
    "print(\"\\nSauvegarde du pipeline grid search\") \n",
    "filename = 'thebestone1.pkl'\n",
    "pickle.dump(pipeline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On charge le modèle entraîné ci dessus et on teste les prédictions sur des données que le modèle n'a jamais vu, ni en entraînement ni en validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle \n",
      "\n",
      "A partir d'un nouveau texte\n",
      "\n",
      "Utilisation d'un texte\n",
      "\n",
      "                                                 data  target\n",
      "0                                Estes Park Colorado        1\n",
      "1   The most beautiful mountain range in the Dolom...       0\n",
      "2        Sunset burns over Reflections lake in Alaska       1\n",
      "3   Bloodmoon Canyon - Original composited Lunar E...       0\n",
      "4                Sunset reflections in Wasilla Alaska       1\n",
      "5                                   Kootenai Falls MT       1\n",
      "6                          Sunset Over Lake Superior        0\n",
      "7         Devils Punchbowl Waterfall Arthur's Pass NZ       0\n",
      "8   The Ghost Mountains Kamchatka Photo Isabella T...       0\n",
      "9              Hidden cove at Oswald West Park Oregon       1\n",
      "10                                  Lake Matheson NZ        0\n",
      "11       Black basalt waterfall at Svartifoss Iceland       0\n",
      "12                      Port Orford Oregon at sunset        1\n",
      "13                    Rattlesnake Lake North Bend WA        1\n",
      "14  Took a hike through the photo archives and fou...       1\n",
      "15  The water of Lake Louise is as clear as glass ...       0\n",
      "16                Sunrise at Tanay Rizal Philippines        0\n",
      "17                           The Grand Canyon Arizona       1\n",
      "18               Sunset at Ecola National Park Oregon       1\n",
      "19  Looking forward to summer again Gimmelwald Swi...       0\n",
      "20  Warm light flooding the Sebalder Reichswald ne...       0\n",
      "21               Views of Denali and the Alaska Range       1\n",
      "22  Richea scoparia on kunanyi/Mt Wellington - Tas...       0\n",
      "23                      Shymbulak mountain Kazakhstan       0\n",
      "24                   Picos de Europa Asturias Spain         0\n",
      "25                                 Gunnison Colorado        1\n",
      "26                Spring Flower at Sunrise in Arizona       1\n",
      "27  The forest reclaiming the mountainside Glacier...       1\n",
      "28   A soft sunset at the UK's Pulpit Rock in Dorset        0\n",
      "29                years old English oak Wiltshire UK        0\n",
      "Sélection aléatoire de 15 documents \n",
      "\n",
      "Prédiction des news séléctionnées\n",
      "\n",
      "Valeurs réelles vs. valeurs prédites\n",
      "\n",
      "texte  13 \t réelle  1  prédite  1\n",
      "texte  14 \t réelle  1  prédite  1\n",
      "texte  4 \t réelle  1  prédite  1\n",
      "texte  13 \t réelle  1  prédite  1\n",
      "texte  1 \t réelle  0  prédite  0\n",
      "texte  9 \t réelle  1  prédite  1\n",
      "texte  6 \t réelle  0  prédite  0\n",
      "texte  12 \t réelle  1  prédite  0\n",
      "texte  11 \t réelle  0  prédite  0\n",
      "texte  5 \t réelle  1  prédite  1\n",
      "texte  8 \t réelle  0  prédite  0\n",
      "texte  2 \t réelle  1  prédite  1\n",
      "texte  10 \t réelle  0  prédite  0\n",
      "texte  9 \t réelle  1  prédite  1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (\"Chargement du modèle \\n\")\n",
    "filename = 'thebestone1.pkl'\n",
    "clf_loaded = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "\n",
    "print (\"A partir d'un nouveau texte\\n\")\n",
    "print (\"Utilisation d'un texte\\n\")\n",
    "\n",
    "df=pd.read_csv(\"newfile.csv\",sep=',', names = ['data', 'target'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "print (\"Sélection aléatoire de 15 documents \\n\")\n",
    "from random import randint\n",
    "samples=[]\n",
    "samples_result=[]\n",
    "sample_new=[]\n",
    "\n",
    "for i in range(1,15):\n",
    "    val=randint(1,15)\n",
    "    sample_new.append(val)\n",
    "    samples.append(df.data[val])\n",
    "    samples_result.append(df.target[val])\n",
    "    \n",
    "print (\"Prédiction des news séléctionnées\\n\")    \n",
    "    \n",
    " \n",
    "\n",
    "result = clf_loaded.predict(samples)\n",
    "\n",
    "print (\"Valeurs réelles vs. valeurs prédites\\n\") \n",
    "for i in range(len(result)):\n",
    "    print (\"texte \",sample_new[i], \n",
    "           \"\\t réelle \", \n",
    "           samples_result[i], \n",
    "           \" prédite \",\n",
    "           result [i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ici on voit que Presque toutes les valeurs prédites sont égales au valeurs réelles, comme le laissait penser les accuracy trouvées plus haut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
